# @title Treinamento para MountainCar-v0
desafio = "MountainCar-v0"

def recompensa_tardia(env, obs, action, next_obs):
    if obs[1] >= 0.5:
      return 1.0
    return -0.1

#RL_ALGORITHMS = [A2C, DDPG, DQN, HER, PPO, SAC, TD3]
RL_ALGORITHMS = [DQN]
for RL in RL_ALGORITHMS:
    nome_algoritmo = str(RL).split('.')[-1].upper()
    nome_modelo = f"/content/Modelo{nome_algoritmo}_Gym_{desafio}"
    print(nome_modelo)
    env = Monitor(gym.make(desafio))
    nome_modelo = f"/content/ModeloDQN_Gym_{desafio}"
    # modelo = DQN("MlpPolicy", env, verbose=1)
    modelo = DQN(
      "MlpPolicy",
      env,
      verbose=1,
      train_freq=16,
      gradient_steps=8,
      gamma=0.99,
      exploration_fraction=0.2,
      exploration_final_eps=0.07,
      target_update_interval=600,
      learning_starts=1000,
      buffer_size=10000,
      batch_size=128,
      learning_rate=4e-3,
      policy_kwargs=dict(net_arch=[256, 256]),
      # tensorboard_log=tensorboard_log,
      seed=2,
    )
    # modelo.learn(total_timesteps=200000)
    modelo.learn(total_timesteps=200000, callback=PlottingCallback())
    modelo.save(nome_modelo)



    